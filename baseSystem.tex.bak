\def\year{2015}
\documentclass[letterpaper]{article}

\usepackage{aaai}
\usepackage{times}
\usepackage{helvet}
\usepackage{courier}

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}

\usepackage{algorithm}
\usepackage{algpseudocode}

\frenchspacing
\setlength{\pdfpagewidth}{8.5in}
\setlength{\pdfpageheight}{11in}

\pdfinfo{
/Title (Insert Your Title Here)
/Author (Put All Your Authors Here, Separated by Commas)}

\setcounter{secnumdepth}{0}  

\input{macros}
\usepackage[textsize=footnotesize,color=green!40]{todonotes}
\newcommand{\borja}[1]{\todo[inline,color=green!40]{{\it Borja:~}#1}}
\newcommand{\doina}[1]{\todo[inline,color=red!40]{{\it Doina:~}#1}}
\newcommand{\lucas}[1]{\todo[inline,color=blue!40]{{\it Lucas:~}#1}}

\begin{document}

\title{Learning Multi-Step Predictive State Representations}
\author{Anonymous Submission}
\maketitle

\begin{abstract}
\begin{quote}
Recent years have seen the development of efficient and provably correct spectral algorithms for learning models of partially observable environments arising in many applications. But despite the high hopes raised by this new class of algorithms, their practical impact is still below expectations. One reason for this is the difficulty in adapting spectral methods to exploit structural constraints about different target environments which can be known beforehand. A natural structure intrinsic to many dynamical systems is a multi-resolution behaviour where interesting phenomena occur at different time scales during the evolution of the system. In this paper we introduce the multi-step predictive state representation (M-PSR) and an associated learning algorithm that finds and leverages frequent patterns of observations at multiple scales in dynamical systems with discrete observations. We perform experiments on robot exploration tasks in a wide variety of environments and conclude that the use of M-PSR improves over the classical PSR for varying amounts of data, environment sizes, and number of observations symbols.

%A standard problem in machine learning is making accurate predictions in partially observable environments. Spectral algorithms which learn PSRs offer statistical consistency, but often have trouble with computational efficiency as the models they learn are too large. In practice, one solves this computational issue by truncating the original model, eliminating the weakest states. Despite this, performance with reduced models is often quite poor. With this issue in mind, we develop a novel extension to PSRs which we call Multi-PSRs. In addition, we provide two algorithms for M-PSRs, one for learning parameters and the other for making effective queries. The M-PSR leverages structure in observations sequences and expresses queries more compactly. This extended model shares all the benefits of the traditional PSR but performs far better for smaller models in experiments. We perform experiments of robot exploration in labyrinth environments and cover both the single observation case (timing) and the multiple observation case. We pick these environments as PSRs have been used for planning applications on these kinds of environments in the past (CITE). In our experiments, we show that the improvement of M-PSRs hold for varying amounts of data, environment sizes, and number of observations symbols.
\end{quote}
\end{abstract}

\input{intro}
\input{mpsr}
\input{algorithms}
\input{experiments}
\input{discussion}

%\section{Acknowledgments}
%Funding and friends...

%\input{appendix}

\bibliographystyle{aaai}
\bibliography{references}

\end{document}
